{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b26601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hp/miniconda3/envs/rs_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric_temporal.nn.recurrent import TGCN, EvolveGCNH, A3TGCN\n",
    "from torch_geometric.utils import dropout_edge\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set environment variables for reproducibility and safety\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 1. Configuration & Seeding\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d1c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'movie'\n",
    "n_clusters = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427345c",
   "metadata": {},
   "source": [
    "## 1. Creating Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e020ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df = pd.read_csv(f'./data/{name}/{name}_processed_interactions.csv')\n",
    "interaction_df['timestamp'] = pd.to_datetime(interaction_df['timestamp'])\n",
    "interaction_df = interaction_df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "interaction_df['year'] = interaction_df['timestamp'].dt.year\n",
    "interaction_df['month'] = interaction_df['timestamp'].dt.month\n",
    "interaction_df['week'] = interaction_df['timestamp'].dt.isocalendar().week\n",
    "# Simple season mapping (1:Winter, 2:Spring, 3:Summer, 4:Fall)\n",
    "interaction_df['season'] = interaction_df['month'].apply(lambda x: (x%12 + 3)//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ed843",
   "metadata": {},
   "source": [
    "### 1.1 Creating Temporal Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6356ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Handle Cyclical Features (Month, Week, Season)\n",
    "# We transform \"Month\" into two dimensions: sin_month and cos_month.\n",
    "# This places months on a unit circle.\n",
    "def encode_cyclic(data, max_val):\n",
    "    data_norm = 2 * np.pi * data / max_val\n",
    "    return np.sin(data_norm), np.cos(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee9eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_stat.shape: (5231, 7)\n",
      "f_stat.columns: Index(['timestamp', 'season_sin', 'season_cos', 'month_sin', 'month_cos',\n",
      "       'week_sin', 'week_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "interaction_df['month_sin'], interaction_df['month_cos'] = encode_cyclic(interaction_df['month'], 12)\n",
    "interaction_df['week_sin'], interaction_df['week_cos'] = encode_cyclic(interaction_df['week'], 52)\n",
    "interaction_df['season_sin'], interaction_df['season_cos'] = encode_cyclic(interaction_df['season'], 4)\n",
    "\n",
    "feature_cols = [\n",
    "    'season_sin', 'season_cos',\n",
    "    'month_sin', 'month_cos', \n",
    "    'week_sin', 'week_cos',\n",
    "]\n",
    "\n",
    "f_stat = interaction_df[['timestamp'] + feature_cols] # dataframe\n",
    "f_stat = f_stat.drop_duplicates()\n",
    "\n",
    "print(f\"f_stat.shape: {f_stat.shape}\")    # Feature Matrix Shape: (5919, 7)\n",
    "print(f'f_stat.columns: {f_stat.columns}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd4872",
   "metadata": {},
   "source": [
    "### 1.2 Creating Temporal Structure Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "795e8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_structural_features(df, interaction_count_col='interaction_count', \n",
    "                                gaps=[90, 30, 7, 1]):\n",
    "    \"\"\"\n",
    "    Calculates 1st and 2nd order structural features (z' and z'') for specified gaps.\n",
    "    print(f_stat.tail(1))\n",
    "    Parameters:\n",
    "    - df: DataFrame containing time-series data.\n",
    "    - interaction_count_col: Name of the column containing interaction counts (z(i)).\n",
    "    - gaps: List of window sizes (default: [90, 30, 7, 1] for season, month, week, day).\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with new columns for each gap (z_prime and z_double_prime).\n",
    "    \"\"\"\n",
    "    \n",
    "    # We work on a copy to avoid Modifying the original dataframe\n",
    "    result_df = df.copy()\n",
    "    result_df = result_df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Extract the base interaction series z(i)\n",
    "    z = result_df[interaction_count_col]\n",
    "    \n",
    "    feature_list = []\n",
    "    \n",
    "    for gap in gaps:\n",
    "        # --- 1. First-Order Structural Feature: z'_{gap}(t) ---\n",
    "        # Formula: (Sum(current_window) - Sum(previous_window)) / gap\n",
    "        \n",
    "        # Calculate rolling sum for the current window [t-gap, t]\n",
    "        # This corresponds to Sum_{i=t-gap}^{t} z(i)\n",
    "        current_sum = z.rolling(window=gap, min_periods=gap).sum()\n",
    "        \n",
    "        # The previous window sum is just the current sum shifted by 'gap'\n",
    "        # This corresponds to Sum_{i=t-2gap}^{t-gap} z(i)\n",
    "        prev_sum = current_sum.shift(gap)\n",
    "        \n",
    "        # Calculate z'\n",
    "        z_prime = (current_sum - prev_sum) / gap\n",
    "        \n",
    "        # Rename for storage\n",
    "        z_prime_col_name = f'z_prime_{gap}'\n",
    "        result_df[z_prime_col_name] = z_prime\n",
    "        \n",
    "        # --- 2. Second-Order Structural Feature: z''_{gap}(t) ---\n",
    "        # Formula: (Sum(current_window_of_z') - Sum(previous_window_of_z')) / gap\n",
    "        \n",
    "        # Now we apply the same rolling logic to the z_prime series we just created\n",
    "        current_sum_prime = z_prime.rolling(window=gap, min_periods=gap).sum()\n",
    "        prev_sum_prime = current_sum_prime.shift(gap)\n",
    "\n",
    "        # Calculate z''\n",
    "        z_double_prime = (current_sum_prime - prev_sum_prime) / gap\n",
    "        \n",
    "        # Rename for storage\n",
    "        z_double_prime_col_name = f'z_double_prime_{gap}'\n",
    "        result_df[z_double_prime_col_name] = z_double_prime\n",
    "        \n",
    "        # --- 3. Padding (Handling Initial NaNs) ---\n",
    "        # The paper states: \"padding... with the nearest timestamp's temporal structural feature\"\n",
    "        # Because we used rolling windows, the beginning of the series will have NaNs.\n",
    "        # We use backfill (bfill) to propagate the first valid observation backwards.\n",
    "        result_df[z_prime_col_name] = result_df[z_prime_col_name].bfill()\n",
    "        result_df[z_double_prime_col_name] = result_df[z_double_prime_col_name].bfill()\n",
    "        \n",
    "        # Keep track of feature names for the final concatenation\n",
    "        feature_list.extend([z_prime_col_name, z_double_prime_col_name])\n",
    "\n",
    "    # Return only the extracted features (concatenated as per Eq 2)\n",
    "    return result_df[['timestamp'] + feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dceab660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_stru: (5231, 9)\n",
      "f_stru: Index(['timestamp', 'z_prime_90', 'z_double_prime_90', 'z_prime_30',\n",
      "       'z_double_prime_30', 'z_prime_7', 'z_double_prime_7', 'z_prime_1',\n",
      "       'z_double_prime_1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "daily_interaction_count_df = interaction_df.groupby('timestamp').size().reset_index(name='interaction_count')\n",
    "daily_interaction_count_df = daily_interaction_count_df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "# Extract Features\n",
    "f_stru = calculate_structural_features(daily_interaction_count_df, \n",
    "                                        gaps=[90, 30, 7, 1])    #dataframe\n",
    "\n",
    "# Check shape (Should have 9 columns: 1 for timestamp and 2 for each of the 4 gaps)\n",
    "print(f\"f_stru: {f_stru.shape}\")    #Feature Matrix Shape: (5919, 9)\n",
    "print(f\"f_stru: {f_stru.columns}\")    #Feature Matrix Shape: (5919, 9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe00118",
   "metadata": {},
   "source": [
    "### 1.3 Concat Temporal Statistical Features and Temporal Structure Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a18a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_stat.shape: (5231, 7)\n",
      "f_stru.shape: (5231, 9)\n",
      "f_all.shape: (5231, 15)\n"
     ]
    }
   ],
   "source": [
    "f_all = pd.merge(f_stat, f_stru, on='timestamp', how='inner')\n",
    "\n",
    "print(f'f_stat.shape: {f_stat.shape}')\n",
    "print(f'f_stru.shape: {f_stru.shape}')\n",
    "print(f'f_all.shape: {f_all.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61533421",
   "metadata": {},
   "source": [
    "### 1.4 Clustering time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eeac3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_all.shape: (5231, 16)\n",
      "f_all.columns: Index(['timestamp', 'season_sin', 'season_cos', 'month_sin', 'month_cos',\n",
      "       'week_sin', 'week_cos', 'z_prime_90', 'z_double_prime_90', 'z_prime_30',\n",
      "       'z_double_prime_30', 'z_prime_7', 'z_double_prime_7', 'z_prime_1',\n",
      "       'z_double_prime_1', 'cluster_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# # Apply K-Means\n",
    "kmeans = KMeans(n_clusters= n_clusters, random_state=42, n_init=10)\n",
    "\n",
    "f_all_feature_only = f_all.drop('timestamp', axis=1)\n",
    "f_all['cluster_label'] = kmeans.fit_predict(f_all_feature_only)\n",
    "\n",
    "print(f'f_all.shape: {f_all.shape}')\n",
    "print(f'f_all.columns: {f_all.columns}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ce035b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCKG_df.shape: (61090, 32)\n",
      "TCKG_df.columns: Index(['user_id', 'entity_id', 'timestamp', 'user_id:token', 'entity_id:token',\n",
      "       'item_id:token', 'rating:float', 'year', 'month', 'week', 'season',\n",
      "       'month_sin_x', 'month_cos_x', 'week_sin_x', 'week_cos_x',\n",
      "       'season_sin_x', 'season_cos_x', 'season_sin_y', 'season_cos_y',\n",
      "       'month_sin_y', 'month_cos_y', 'week_sin_y', 'week_cos_y', 'z_prime_90',\n",
      "       'z_double_prime_90', 'z_prime_30', 'z_double_prime_30', 'z_prime_7',\n",
      "       'z_double_prime_7', 'z_prime_1', 'z_double_prime_1', 'cluster_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "temporal_interaction_df = pd.merge(interaction_df, f_all, on='timestamp', how='inner')\n",
    "print(f'TCKG_df.shape: {temporal_interaction_df.shape}')\n",
    "print(f'TCKG_df.columns: {temporal_interaction_df.columns}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08be9fd",
   "metadata": {},
   "source": [
    "## 2. Create TCKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b651475",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = pd.read_csv(f'./data/{name}/{name}_processed_graph.csv')\n",
    "\n",
    "temporal_interaction_df = temporal_interaction_df.rename(columns={'user_id': 'head_id', \n",
    "                                            'entity_id': 'tail_id',\n",
    "                                            'user_id:token': 'head_id:token',\n",
    "                                            'entity_id:token': 'tail_id:token'})\n",
    "\n",
    "max_relation_id_in_graph = graph_df['relation_id'].max()\n",
    "\n",
    "temporal_interaction_df['relation_id'] = temporal_interaction_df['cluster_label'] + max_relation_id_in_graph   # new relation_id\n",
    "temporal_interaction_df['relation_id:token'] = 'interacted_' + temporal_interaction_df['cluster_label'].astype(str)  # new relation_id:token\n",
    "\n",
    "temporal_interaction_df = temporal_interaction_df[['head_id', 'relation_id', 'tail_id',\n",
    "                                'head_id:token', 'relation_id:token', 'tail_id:token']]\n",
    "                            \n",
    "TCKG_df = pd.concat([graph_df, temporal_interaction_df], ignore_index=True)\n",
    "TCKG_df.to_csv(f'./data/{name}/{name}_TCKG.csv', index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e73d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

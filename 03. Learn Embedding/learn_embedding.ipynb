{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8b26601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Set environment variables for reproducibility and safety\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 1. Configuration & Seeding\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "00d1c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'movie'\n",
    "n_clusters = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427345c",
   "metadata": {},
   "source": [
    "## 1. Learn Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16a21a",
   "metadata": {},
   "source": [
    "### 1.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d4bf5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCKGDataset(Dataset):\n",
    "    def __init__(self, triplets):\n",
    "        self.triplets = triplets\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    def __getitem__(self, idx):\n",
    "        # Trảmovie về bộ ba (head, relation, tail)\n",
    "        return self.triplets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae3ed5",
   "metadata": {},
   "source": [
    "### 1.2 TransE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28e020ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(pl.LightningModule):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim=64, lr=1e-3, weight_decay=1e-4, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Khởi tạo Embeddings\n",
    "        self.entity_emb = nn.Embedding(num_entities + 1, embedding_dim, padding_idx=0)     # +1 because starting at 1 instead of 0\n",
    "        self.relation_emb = nn.Embedding(num_relations + 1, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # # Xavier initialization giúp hội tụ tốt hơn\n",
    "        # nn.init.xavier_uniform_(self.entity_emb.weight)\n",
    "        # nn.init.xavier_uniform_(self.relation_emb.weight)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, h, r, t):\n",
    "        h_e = self.entity_emb(h)\n",
    "        r_e = self.relation_emb(r)\n",
    "        t_e = self.entity_emb(t)\n",
    "\n",
    "        # 2. Embedding Normalization (Rất quan trọng cho TransE)\n",
    "        # Ép độ dài các vector về 1 (Unit Norm constraint)\n",
    "        h_e = F.normalize(h_e, p=2, dim=1)\n",
    "        r_e = F.normalize(r_e, p=2, dim=1)\n",
    "        t_e = F.normalize(t_e, p=2, dim=1)\n",
    "        \n",
    "        # 3. Áp dụng Dropout\n",
    "        h_e = self.dropout(h_e)\n",
    "        r_e = self.dropout(r_e)\n",
    "        t_e = self.dropout(t_e)\n",
    "        \n",
    "        # Công thức (6): Khoảng cách bình phương L2\n",
    "        # g_r(h, t) = ||h + r - t||^2\n",
    "        score = torch.sum((h_e + r_e - t_e)**2, dim=1)\n",
    "        return score\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        h, r, t = batch[:, 0], batch[:, 1], batch[:, 2]\n",
    "        \n",
    "        # Tính score cho bộ ba đúng (Positive) -> Cần giảm thiểu khoảng cách này\n",
    "        pos_scores = self(h, r, t)\n",
    "        \n",
    "        # Negative Sampling: Thay thế tail t bằng t' ngẫu nhiên\n",
    "        # t' không nhất thiết phải là không đúng thực tế (simplified), nhưng xác suất cao là không đúng.\n",
    "        rand_t = torch.randint(1, self.hparams.num_entities + 1, t.shape, device=self.device)\n",
    "        \n",
    "        # Tính score cho bộ ba sai (Negative) -> Cần tối đa hóa khoảng cách này\n",
    "        neg_scores = self(h, r, rand_t)\n",
    "        \n",
    "        # Công thức (7) Loss: -ln(sigmoid(g_neg - g_pos))\n",
    "        # Chúng ta muốn g_neg > g_pos (khoảng cách sai lớn hơn đúng)\n",
    "        # => (g_neg - g_pos) càng lớn càng tốt\n",
    "        loss = -F.logsigmoid(neg_scores - pos_scores).mean()\n",
    "        \n",
    "        # Log loss\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        h, r, t = batch[:, 0], batch[:, 1], batch[:, 2]\n",
    "        \n",
    "        # 1. Tính loss trên valid set\n",
    "        pos_scores = self(h, r, t)\n",
    "        \n",
    "        # Negative sampling (đơn giản hoá để tính loss theo dõi)\n",
    "        rand_t = torch.randint(1, self.hparams.num_entities + 1, t.shape, device=self.device)\n",
    "\n",
    "        neg_scores = self(h, r, rand_t)\n",
    "        \n",
    "        val_loss = -F.logsigmoid(neg_scores - pos_scores).mean()\n",
    "        self.log('val_loss', val_loss, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # 4. Thêm weight_decay (L2 regularization) vào Adam\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a4929",
   "metadata": {},
   "source": [
    "### 1.3 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "576d8ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./data/movie_TCKG.csv...\n",
      "triplets_tensor.shape: torch.Size([164383, 3])\n"
     ]
    }
   ],
   "source": [
    "file_path = f'./data/{name}_TCKG.csv' \n",
    "print(f\"Loading data from {file_path}...\")\n",
    "\n",
    "TCKG_df = pd.read_csv(file_path)\n",
    "\n",
    "# Chuyển đổi dữ liệu sang index\n",
    "triplets_np = np.stack([\n",
    "    TCKG_df['head_id'],\n",
    "    TCKG_df['relation_id'],\n",
    "    TCKG_df['tail_id']\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "# Chuyển sang Tensor\n",
    "triplets_tensor = torch.tensor(triplets_np, dtype=torch.long)\n",
    "print(f'triplets_tensor.shape: {triplets_tensor.shape}')\n",
    "\n",
    "# Tạo DataLoader\n",
    "full_dataset = TCKGDataset(triplets_tensor)\n",
    "\n",
    "# Chia 90% Train - 10% Val\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_set, val_set = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Tạo 2 Loaders\n",
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=1024, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a424b4",
   "metadata": {},
   "source": [
    "### 1.3 Init and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1fb6af53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name         | Type      | Params | Mode  | FLOPs\n",
      "-----------------------------------------------------------\n",
      "0 | entity_emb   | Embedding | 3.7 M  | train | 0    \n",
      "1 | relation_emb | Embedding | 1.6 K  | train | 0    \n",
      "2 | dropout      | Dropout   | 0      | train | 0    \n",
      "-----------------------------------------------------------\n",
      "3.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.7 M     Total params\n",
      "14.990    Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entities: 58529\n",
      "Total Relations: 24\n",
      "Epoch 0:   0%|          | 0/145 [00:00<?, ?it/s]                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1982.33s - thread._ident is None in _get_related_thread!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 145/145 [00:15<00:00,  9.33it/s, v_num=0, train_loss=0.809, val_loss=0.726]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 145/145 [00:13<00:00, 10.55it/s, v_num=0, train_loss=0.840, val_loss=0.724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.001. New best score: 0.724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/145 [00:00<?, ?it/s, v_num=0, train_loss=0.840, val_loss=0.724]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2012.78s - thread._ident is None in _get_related_thread!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 145/145 [00:14<00:00, 10.05it/s, v_num=0, train_loss=0.779, val_loss=0.719]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.001. New best score: 0.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 145/145 [00:13<00:00, 10.87it/s, v_num=0, train_loss=0.776, val_loss=0.718]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.001. New best score: 0.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 145/145 [00:11<00:00, 12.12it/s, v_num=0, train_loss=0.780, val_loss=0.715]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.001. New best score: 0.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 145/145 [00:12<00:00, 11.88it/s, v_num=0, train_loss=0.812, val_loss=0.715]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2064.56s - thread._ident is None in _get_related_thread!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 145/145 [00:13<00:00, 10.95it/s, v_num=0, train_loss=0.812, val_loss=0.709]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.001. New best score: 0.709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  90%|████████▉ | 130/145 [00:09<00:01, 13.03it/s, v_num=0, train_loss=0.790, val_loss=0.709]"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hp/Study/07. Luan Van/03. TPRec/03. Learn Embedding/lightning_logs/version_0/metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:630\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    624\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    625\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    626\u001b[39m     ckpt_path,\n\u001b[32m    627\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    628\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    629\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1079\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path, weights_only)\u001b[39m\n\u001b[32m   1076\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1077\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1078\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1082\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1083\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1123\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:217\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:465\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:153\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:384\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# SAVE METRICS TO LOGGERS AND PROGRESS_BAR\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_logger_connector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_train_step_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:166\u001b[39m, in \u001b[36m_LoggerConnector.update_train_step_metrics\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.should_update_logs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.fast_dev_run:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlog\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:120\u001b[39m, in \u001b[36m_LoggerConnector.log_metrics\u001b[39m\u001b[34m(self, metrics, step)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.loggers:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalar_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     logger.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py:41\u001b[39m, in \u001b[36mrank_zero_only.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_fabric/loggers/csv_logs.py:154\u001b[39m, in \u001b[36mCSVLogger.log_metrics\u001b[39m\u001b[34m(self, metrics, step)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (step + \u001b[32m1\u001b[39m) % \u001b[38;5;28mself\u001b[39m._flush_logs_every_n_steps == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py:41\u001b[39m, in \u001b[36mrank_zero_only.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_fabric/loggers/csv_logs.py:160\u001b[39m, in \u001b[36mCSVLogger.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28msuper\u001b[39m().save()\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_fabric/loggers/csv_logs.py:240\u001b[39m, in \u001b[36m_ExperimentWriter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m._rewrite_with_new_header(\u001b[38;5;28mself\u001b[39m.metrics_keys)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetrics_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_exists\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m    241\u001b[39m     writer = csv.DictWriter(file, fieldnames=\u001b[38;5;28mself\u001b[39m.metrics_keys)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/spec.py:1337\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1331\u001b[39m     text_kwargs = {\n\u001b[32m   1332\u001b[39m         k: kwargs.pop(k)\n\u001b[32m   1333\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnewline\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1334\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m   1335\u001b[39m     }\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m io.TextIOWrapper(\n\u001b[32m-> \u001b[39m\u001b[32m1337\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m            \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1345\u001b[39m         **text_kwargs,\n\u001b[32m   1346\u001b[39m     )\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/spec.py:1349\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1348\u001b[39m ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1349\u001b[39m f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/implementations/local.py:210\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/implementations/local.py:387\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/implementations/local.py:392\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m     \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/hp/Study/07. Luan Van/03. TPRec/03. Learn Embedding/lightning_logs/version_0/metrics.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     36\u001b[39m trainer = pl.Trainer(\n\u001b[32m     37\u001b[39m     max_epochs=\u001b[32m50\u001b[39m, \n\u001b[32m     38\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m# Tự động dùng GPU nếu có\u001b[39;00m\n\u001b[32m     39\u001b[39m     callbacks=[checkpoint_callback, early_stop_callback],\n\u001b[32m     40\u001b[39m     enable_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     41\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Bắt đầu huấn luyện\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Sau khi train, bạn có thể lấy embedding bằng:\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# entity_embeddings = model.entity_emb.weight.detach().cpu().numpy()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:584\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:69\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m     sys.exit(\u001b[32m1\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43m_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     trainer._teardown()\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:83\u001b[39m, in \u001b[36m_interrupt\u001b[39m\u001b[34m(trainer, exception)\u001b[39m\n\u001b[32m     81\u001b[39m trainer.strategy.on_exception(exception)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer.loggers:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfailed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py:41\u001b[39m, in \u001b[36mrank_zero_only.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_fabric/loggers/csv_logs.py:169\u001b[39m, in \u001b[36mCSVLogger.finalize\u001b[39m\u001b[34m(self, status)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# When using multiprocessing, finalize() should be a no-op on the main process, as no experiment has been\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# initialized there\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py:41\u001b[39m, in \u001b[36mrank_zero_only.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_fabric/loggers/csv_logs.py:160\u001b[39m, in \u001b[36mCSVLogger.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;129m@rank_zero_only\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    159\u001b[39m     \u001b[38;5;28msuper\u001b[39m().save()\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/lightning_fabric/loggers/csv_logs.py:240\u001b[39m, in \u001b[36m_ExperimentWriter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_keys \u001b[38;5;129;01mand\u001b[39;00m file_exists:\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# we need to re-write the file if the keys (header) change\u001b[39;00m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m._rewrite_with_new_header(\u001b[38;5;28mself\u001b[39m.metrics_keys)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetrics_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_exists\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m    241\u001b[39m     writer = csv.DictWriter(file, fieldnames=\u001b[38;5;28mself\u001b[39m.metrics_keys)\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists:\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# only write the header if we're writing a fresh file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/spec.py:1337\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     mode = mode.replace(\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1331\u001b[39m     text_kwargs = {\n\u001b[32m   1332\u001b[39m         k: kwargs.pop(k)\n\u001b[32m   1333\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnewline\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1334\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m   1335\u001b[39m     }\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m io.TextIOWrapper(\n\u001b[32m-> \u001b[39m\u001b[32m1337\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m            \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1345\u001b[39m         **text_kwargs,\n\u001b[32m   1346\u001b[39m     )\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1348\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/spec.py:1349\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1348\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1349\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1358\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/implementations/local.py:210\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/implementations/local.py:387\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28mself\u001b[39m.compression = get_compression(path, compression)\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rs_env/lib/python3.11/site-packages/fsspec/implementations/local.py:392\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f.closed:\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m         \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n\u001b[32m    394\u001b[39m             compress = compr[\u001b[38;5;28mself\u001b[39m.compression]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/hp/Study/07. Luan Van/03. TPRec/03. Learn Embedding/lightning_logs/version_0/metrics.csv'"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "num_entites = pd.concat([TCKG_df['head_id'], TCKG_df['tail_id']]).max()\n",
    "num_relations = TCKG_df['relation_id'].max()\n",
    "\n",
    "print(f\"Total Entities: {num_entites}\")\n",
    "print(f\"Total Relations: {num_relations}\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',       # Theo dõi val_loss\n",
    "    dirpath=f'./checkpoints/', # Thư mục lưu\n",
    "    filename=f'{name}-transE-{timestamp}-{{epoch:02d}}-{{val_loss:.4f}}', \n",
    "    save_top_k=1,             # Chỉ giữ lại 1 model tốt nhất\n",
    "    mode='min',               # Lưu khi val_loss nhỏ nhất\n",
    ")\n",
    "\n",
    "# 5. Early Stopping Callback\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss', # Theo dõi val_loss\n",
    "    min_delta=0.001,    # Cải thiện tối thiểu cần thiết\n",
    "    patience=10,         # Chờ 5 epochs nếu không cải thiện thì dừng\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model = TransE(\n",
    "    num_entities=num_entites, \n",
    "    num_relations=num_relations, \n",
    "    embedding_dim=64, # Có thể chỉnh d-dimension tại đây\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-3,  # Tăng lên nếu vẫn overfit (ví dụ: 1e-3)\n",
    "    dropout_rate=0.3    # Tăng lên nếu vẫn overfit (tối đa 0.5)\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50, \n",
    "    accelerator=\"auto\", # Tự động dùng GPU nếu có\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "# Bắt đầu huấn luyện\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "# Sau khi train, bạn có thể lấy embedding bằng:\n",
    "# entity_embeddings = model.entity_emb.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188aed9",
   "metadata": {},
   "source": [
    "### 1.5 Save trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9129a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract Embeddings from Model (move to CPU and convert to numpy)\n",
    "entity_embeddings = model.entity_emb.weight.detach().cpu().numpy()\n",
    "relation_embeddings = model.relation_emb.weight.detach().cpu().numpy()\n",
    "\n",
    "# 2. Package everything into a dictionary\n",
    "saved_data = {\n",
    "    'entity_embeddings': entity_embeddings,      # (Num_Entities, dim)\n",
    "    'relation_embeddings': relation_embeddings,  # (Num_Relations, dim)\n",
    "}\n",
    "# 3. Save to a single file\n",
    "with open(f'./pickle/{name}_transE_embeddings_{timestamp}.pkl', 'wb') as f:\n",
    "    pickle.dump(saved_data, f)\n",
    "print(\"Embeddings and mappings saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

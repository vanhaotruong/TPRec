{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe13638",
   "metadata": {},
   "source": [
    "1. Ví dụ, trong tháng 1 có 250 interaction, tháng 2 có 300 interaction, tháng 3 có 280, tháng 4 có 320, tháng 5 có 190. tôi lấy 4 tháng đầu để predict tháng 5. Vậy trong trainig_step của tôi nó tính loss như thế nào\n",
    "\n",
    "\n",
    "Đây là ví dụ rất cụ thể và hay để hình dung luồng đi của dữ liệu. Hãy cùng mổ xẻ quá trình này theo từng bước trong code:\n",
    "\n",
    "Tình huống: Bạn đang train cho Tháng 5 (Target). Dữ liệu đầu vào (History): Tháng 1, 2, 3, 4. Dữ liệu nhãn (Ground Truth): 190 interaction của Tháng 5.\n",
    "\n",
    "Quá trình tính Loss trong training_step diễn ra như sau:\n",
    "\n",
    "Bước 1: Sampler bốc Batch (Dữ liệu thật)\n",
    "Sampler sẽ lấy toàn bộ (hoặc một phần) dữ liệu của Tháng 5.\n",
    "\n",
    "Batch chứa: 190 cặp (user, item) ĐÃ XẢY RA trong tháng 5.\n",
    "current_t (time_idx) = chỉ số của tháng 5.\n",
    "Bước 2: Model \"Hồi tưởng\" (Hàm forward)\n",
    "Hàm training_step gọi self(current_t=Tháng 5). Trong forward, model TUYỆT ĐỐI KHÔNG ĐƯỢC NHÌN đồ thị tháng 5. Nó chỉ làm việc sau:\n",
    "\n",
    "Lấy đồ thị Tháng 1 -> đưa vào T-GCN -> ra trạng thái $H_1$.\n",
    "Lấy $H_1$ + đồ thị Tháng 2 -> đưa vào T-GCN -> ra trạng thái $H_2$.\n",
    "Lấy $H_2$ + đồ thị Tháng 3 -> đưa vào T-GCN -> ra trạng thái $H_3$.\n",
    "Lấy $H_3$ + đồ thị Tháng 4 -> đưa vào T-GCN -> ra trạng thái $H_{pred}$.\n",
    "Kết quả: $H_{pred}$ là một bảng Embedding khổng lồ (cho tất cả User/Item) mang ý nghĩa: \"Dựa trên những gì đã xảy ra suốt 4 tháng qua, tôi đoán sở thích của mọi người vào đầu tháng 5 là thế này...\"\n",
    "\n",
    "Bước 3: Tính điểm (Scoring)\n",
    "Quay lại training_step, model cầm bảng $H_{pred}$ để đối chiếu với 190 interaction thật của tháng 5:\n",
    "\n",
    "Positive Score (Điểm cho cặp thật):\n",
    "Với interaction thứ 1 (ví dụ: User A thích Book B): Model tra vào bảng $H_{pred}$, lấy vector User A và Book B nhân với nhau.\n",
    "Làm tương tự cho hết 190 cặp.\n",
    "=> Ra được 190 con số (hy vọng là số lớn, vì model đoán đúng sở thích).\n",
    "Negative Score (Điểm cho cặp ngẫu nhiên):\n",
    "Model bốc ngẫu nhiên 190 cuốn sách khác (User A với Book C \"trên trời rơi xuống\").\n",
    "Model tra bảng $H_{pred}$, nhân vector User A với Book C.\n",
    "=> Ra được 190 con số (hy vọng là số nhỏ, vì User A không thích Book C).\n",
    "Bước 4: Tính Loss (Trừng phạt)\n",
    "Hàm BPR Loss sẽ xem xét sự chênh lệch: $$Loss = - \\log(\\text{sigmoid}(\\text{Điểm Thật} - \\text{Điểm Ngẫu nhiên}))$$\n",
    "\n",
    "Nếu Điểm Thật (Tháng 5) >> Điểm Ngẫu nhiên: Loss nhỏ (Model: \"Tôi đã đoán đúng xu hướng tháng 5 dựa trên tháng 1-4\").\n",
    "Nếu Điểm Thật < Điểm Ngẫu nhiên: Loss lớn (Model: \"Tôi đoán sai bét, cần cập nhật lại trọng số\").\n",
    "Tóm lại\n",
    "Trong training_step này:\n",
    "\n",
    "Đầu vào tính toán: Các cạnh nối của tháng 1, 2, 3, 4.\n",
    "Đáp án để chấm điểm: 190 cạnh nối của tháng 5.\n",
    "Logic: Dùng quá khứ (1-4) để tạo embedding sao cho nó khớp nhất với tương lai (5)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

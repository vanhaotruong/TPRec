import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

def analyze_interaction_density(df, user_col='user_id', item_col='entity_id'):
    """
    PhÃ¢n tÃ­ch máº­t Ä‘á»™ tÆ°Æ¡ng tÃ¡c cá»§a User vÃ  Item Ä‘á»ƒ chá»n k-core phÃ¹ há»£p.
    """
    print("="*50)
    print("ğŸ” BÃO CÃO Máº¬T Äá»˜ TÆ¯Æ NG TÃC Tá»”NG QUAN")
    print("="*50)
    
    # 1. Äáº¿m sá»‘ lÆ°á»£ng tÆ°Æ¡ng tÃ¡c cá»§a tá»«ng User vÃ  Item
    user_counts = df[user_col].value_counts()
    item_counts = df[item_col].value_counts()
    
    print(f"Tá»•ng sá»‘ tÆ°Æ¡ng tÃ¡c (dÃ²ng): {len(df):,}")
    print(f"Tá»•ng sá»‘ Users duy nháº¥t: {len(user_counts):,}")
    print(f"Tá»•ng sá»‘ Items duy nháº¥t: {len(item_counts):,}\n")
    
    # 2. In thá»‘ng kÃª mÃ´ táº£ vá»›i cÃ¡c má»‘c pháº§n trÄƒm quan trá»ng
    percentiles = [0.25, 0.5, 0.75, 0.90, 0.95, 0.99]
    
    print("ğŸ‘¤ THá»NG KÃŠ USER (Má»—i User cÃ³ bao nhiÃªu tÆ°Æ¡ng tÃ¡c?):")
    print(user_counts.describe(percentiles=percentiles).to_string())
    print("-" * 30)
    
    print("ğŸ“¦ THá»NG KÃŠ ITEM (Má»—i Item Ä‘Æ°á»£c tÆ°Æ¡ng tÃ¡c bao nhiÃªu láº§n?):")
    print(item_counts.describe(percentiles=percentiles).to_string())
    print("-" * 30)
    
    # 3. TÃ­nh toÃ¡n thá»­ nghiá»‡m sá»± sá»¥t giáº£m dá»¯ liá»‡u vá»›i cÃ¡c má»©c K khÃ¡c nhau
    print("\nğŸ“‰ MÃ” PHá»NG Náº¾U ÃP Dá»¤NG Lá»ŒC K-CORE (Chá»‰ tÃ­nh riÃªng láº» 1 vÃ²ng):")
    test_k_values = [3, 5, 6, 7, 8, 9, 10]
    
    for k in test_k_values:
        users_kept = (user_counts >= k).sum()
        items_kept = (item_counts >= k).sum()
        
        pct_users = (users_kept / len(user_counts)) * 100
        pct_items = (items_kept / len(item_counts)) * 100
        
        print(f"ğŸ‘‰ K = {k:<2} | Giá»¯ láº¡i {pct_users:>5.1f}% Users ({users_kept}) vÃ  {pct_items:>5.1f}% Items ({items_kept})")

    # 4. Váº½ biá»ƒu Ä‘á»“ trá»±c quan
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # Cáº¯t Ä‘uÃ´i á»Ÿ má»©c 95% Ä‘á»ƒ biá»ƒu Ä‘á»“ khÃ´ng bá»‹ mÃ©o bá»Ÿi cÃ¡c outlier quÃ¡ lá»›n
    user_cutoff = np.percentile(user_counts, 95)
    item_cutoff = np.percentile(item_counts, 95)
    
    axes[0].hist(user_counts[user_counts <= user_cutoff], bins=50, color='skyblue', edgecolor='black')
    axes[0].set_title(f'PhÃ¢n phá»‘i tÆ°Æ¡ng tÃ¡c cá»§a User\n(Bá» qua 5% Users siÃªu tÃ­ch cá»±c)')
    axes[0].set_xlabel('Sá»‘ lÆ°á»£ng tÆ°Æ¡ng tÃ¡c')
    axes[0].set_ylabel('Sá»‘ lÆ°á»£ng User')
    
    axes[1].hist(item_counts[item_counts <= item_cutoff], bins=50, color='lightcoral', edgecolor='black')
    axes[1].set_title(f'PhÃ¢n phá»‘i tÆ°Æ¡ng tÃ¡c cá»§a Item\n(Bá» qua 5% Items siÃªu phá»• biáº¿n)')
    axes[1].set_xlabel('Sá»‘ lÆ°á»£ng tÆ°Æ¡ng tÃ¡c')
    axes[1].set_ylabel('Sá»‘ lÆ°á»£ng Item')
    
    plt.tight_layout()
    plt.show()

# CÃ¡ch dÃ¹ng: (Giáº£ sá»­ file cá»§a báº¡n tÃªn lÃ  data.csv)
name = 'book'
path = '/home/hp/Study/07. Luan Van/03. TPRec/01. Build and split dataset/data/book/book_processed_interactions.csv'
all_dataset = pd.read_csv(path)
analyze_interaction_density(all_dataset, user_col='user_id', item_col='entity_id')